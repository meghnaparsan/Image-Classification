{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDirectory = 'Downloads/DataSet_Split/'\n",
    "categories = ['cardboard', 'plastic', 'glass', 'metal', 'paper', 'trash']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in categories:\n",
    "    path = os.path.join(dataDirectory, category) #Path for each folder\n",
    "    for image in os.listdir(path): #Path for each image of the particular folder\n",
    "        image_array = cv2.imread(os.path.join(path, image), cv2.IMREAD_UNCHANGED) #Image is unchanged (meaning - RGB image)\n",
    "        plt.imshow(image_array)\n",
    "        plt.show()\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since, it is a colored image, the array is 2D and the values ranges from 0 to 255 (RGB)\n",
    "\n",
    "print (image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in categories:\n",
    "    path = os.path.join(dataDirectory, category) #Path for each folder\n",
    "    for image in os.listdir(path): #Path for each image of the particular folder\n",
    "        image_array = cv2.imread(os.path.join(path, image), cv2.IMREAD_GRAYSCALE) #Image is converted into a Gray scale image\n",
    "        plt.imshow(image_array, cmap = 'gray')\n",
    "        plt.show()\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It is a 1D array, as the image is converted into a gray scale image\n",
    "\n",
    "print (image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The data set has images in a highly irregular shape. Normalization is required\n",
    "\n",
    "image_size = 50\n",
    "\n",
    "resized_array = cv2.resize (image_array, (image_size, image_size))\n",
    "plt.imshow(resized_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "image_size = 50\n",
    "\n",
    "def create_training_data():\n",
    "    for category in categories:\n",
    "        path = os.path.join(dataDirectory, category) #Path for each folder\n",
    "        class_number = categories.index(category) #assign a number for each class. \n",
    "        for image in os.listdir(path): #Path for each image of the particular folder\n",
    "            try:\n",
    "                image_array = cv2.imread(os.path.join(path, image), cv2.IMREAD_UNCHANGED) #Image is unchanged (meaning - RGB image)\n",
    "                resized_array = cv2.resize (image_array, (image_size, image_size)) #Resize the images\n",
    "                training_data.append([resized_array, class_number]) \n",
    "            except Exception as e:\n",
    "                pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1977\n"
     ]
    }
   ],
   "source": [
    "create_training_data()\n",
    "\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffling the dataset, so that the model would learn better\n",
    "\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for samples in training_data[:20]:\n",
    "    print (samples[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "labels = []\n",
    "\n",
    "for feat, label in training_data:\n",
    "    features.append(feat)\n",
    "    labels.append(label)\n",
    "    \n",
    "features = np.array(features).reshape(-1, image_size, image_size, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(features[0])\n",
    "plt.show()\n",
    "\n",
    "print (labels[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open('features.pickle', 'wb') #w-write, b-binary\n",
    "pickle.dump(features, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open('labels.pickle', 'wb') #w-write, b-binary\n",
    "pickle.dump(labels, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open ('features.pickle', 'rb')\n",
    "features = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open ('labels.pickle', 'rb')\n",
    "labels = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1779 samples, validate on 198 samples\n",
      "Epoch 1/20\n",
      "1779/1779 [==============================] - 10s 6ms/sample - loss: 13.9114 - accuracy: 0.2485 - val_loss: 1.7885 - val_accuracy: 0.2323\n",
      "Epoch 2/20\n",
      "1779/1779 [==============================] - 8s 4ms/sample - loss: 1.5810 - accuracy: 0.3440 - val_loss: 1.7230 - val_accuracy: 0.2626\n",
      "Epoch 3/20\n",
      "1779/1779 [==============================] - 8s 4ms/sample - loss: 1.4316 - accuracy: 0.4087 - val_loss: 1.9275 - val_accuracy: 0.2576\n",
      "Epoch 4/20\n",
      "1779/1779 [==============================] - 8s 4ms/sample - loss: 1.2740 - accuracy: 0.5003 - val_loss: 1.7839 - val_accuracy: 0.3535\n",
      "Epoch 5/20\n",
      "1779/1779 [==============================] - 8s 5ms/sample - loss: 1.1042 - accuracy: 0.5649 - val_loss: 1.7950 - val_accuracy: 0.3333\n",
      "Epoch 6/20\n",
      "1779/1779 [==============================] - 9s 5ms/sample - loss: 0.9755 - accuracy: 0.6290 - val_loss: 2.0462 - val_accuracy: 0.3838\n",
      "Epoch 7/20\n",
      "1779/1779 [==============================] - 8s 4ms/sample - loss: 0.7808 - accuracy: 0.6993 - val_loss: 2.1491 - val_accuracy: 0.3889\n",
      "Epoch 8/20\n",
      "1779/1779 [==============================] - 8s 5ms/sample - loss: 0.6560 - accuracy: 0.7527 - val_loss: 2.2998 - val_accuracy: 0.3687\n",
      "Epoch 9/20\n",
      "1779/1779 [==============================] - 8s 5ms/sample - loss: 0.6700 - accuracy: 0.7442 - val_loss: 2.8439 - val_accuracy: 0.3889\n",
      "Epoch 10/20\n",
      "1779/1779 [==============================] - 8s 5ms/sample - loss: 0.5778 - accuracy: 0.7808 - val_loss: 2.8339 - val_accuracy: 0.3737\n",
      "Epoch 11/20\n",
      "1779/1779 [==============================] - 8s 5ms/sample - loss: 0.4565 - accuracy: 0.8291 - val_loss: 3.3735 - val_accuracy: 0.3636\n",
      "Epoch 12/20\n",
      "1779/1779 [==============================] - 8s 4ms/sample - loss: 0.4760 - accuracy: 0.8123 - val_loss: 3.2424 - val_accuracy: 0.3586\n",
      "Epoch 13/20\n",
      "1779/1779 [==============================] - 8s 5ms/sample - loss: 0.4241 - accuracy: 0.8336 - val_loss: 3.5659 - val_accuracy: 0.3889\n",
      "Epoch 14/20\n",
      "1779/1779 [==============================] - 8s 4ms/sample - loss: 0.3428 - accuracy: 0.8842 - val_loss: 4.2929 - val_accuracy: 0.3636\n",
      "Epoch 15/20\n",
      "1779/1779 [==============================] - 8s 5ms/sample - loss: 0.3288 - accuracy: 0.8825 - val_loss: 3.8090 - val_accuracy: 0.4192\n",
      "Epoch 16/20\n",
      "1779/1779 [==============================] - 8s 5ms/sample - loss: 0.2728 - accuracy: 0.9168 - val_loss: 4.5415 - val_accuracy: 0.3687\n",
      "Epoch 17/20\n",
      "1779/1779 [==============================] - 8s 4ms/sample - loss: 0.2943 - accuracy: 0.8983 - val_loss: 4.3384 - val_accuracy: 0.4040\n",
      "Epoch 18/20\n",
      "1779/1779 [==============================] - 8s 4ms/sample - loss: 0.2280 - accuracy: 0.9213 - val_loss: 4.8167 - val_accuracy: 0.4394\n",
      "Epoch 19/20\n",
      "1779/1779 [==============================] - 8s 4ms/sample - loss: 0.3781 - accuracy: 0.8758 - val_loss: 4.4289 - val_accuracy: 0.3434\n",
      "Epoch 20/20\n",
      "1779/1779 [==============================] - 8s 5ms/sample - loss: 0.4273 - accuracy: 0.8600 - val_loss: 4.6338 - val_accuracy: 0.3434\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x205af5320b8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = \"Plastic_2x64-{}\".format (int (time.time()))\n",
    "\n",
    "tf_dir = os.path.join(\"logs\", name)\n",
    "tensorBoard = TensorBoard (log_dir =  tf_dir)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3,3), input_shape = features.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation ('relu'))\n",
    "\n",
    "model.add(Dense(6))\n",
    "model.add(Activation ('softmax'))\n",
    "\n",
    "sgd = tf.keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile (loss = 'sparse_categorical_crossentropy', \n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "features = np.asarray(features)\n",
    "labels = np.asarray(labels)\n",
    "\n",
    "model.fit (features, labels, validation_split = 0.1, epochs = 20, callbacks = [tensorBoard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n"
     ]
    }
   ],
   "source": [
    "image_path=\"Downloads/DataSet_Split/Testing/glass/glass10.jpg\"\n",
    "img = image.load_img(image_path, target_size=(50, 50))\n",
    "# plt.imshow(img)\n",
    "\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = tf.cast(img, tf.float32)\n",
    "result=model.predict_classes((img))\n",
    "print (result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
